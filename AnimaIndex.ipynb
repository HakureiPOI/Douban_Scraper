{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HakureiPOI/Douban_Scraper/blob/main/AnimaIndex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKH2T6aVsfas"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "import logging\n",
        "from bs4 import BeautifulSoup\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLuMJ3-dwi7w"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data\n",
        "!mkdir -p logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUdqSfLnwrbj"
      },
      "outputs": [],
      "source": [
        "def setup_logger(name=__name__, log_file='logs/log.txt', level=logging.DEBUG):\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(level)\n",
        "\n",
        "    formatter = logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')\n",
        "\n",
        "    # stream_handler = logging.StreamHandler()\n",
        "    # stream_handler.setFormatter(formatter)\n",
        "    # logger.addHandler(stream_handler)\n",
        "\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setFormatter(formatter)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    return logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ux6b_ZRHwxlc"
      },
      "outputs": [],
      "source": [
        "logger = setup_logger()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvsg_X10y50n"
      },
      "outputs": [],
      "source": [
        "class Interface():\n",
        "    def __init__(self):\n",
        "        self.session = requests.Session()\n",
        "        adapter = requests.adapters.HTTPAdapter(pool_connections = 100, pool_maxsize = 100)\n",
        "        self.session.mount('http://', adapter)\n",
        "        self.session.mount('https://', adapter)\n",
        "        self.user_agent = [\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36',\n",
        "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n",
        "        ]\n",
        "\n",
        "    def _post(self, url, data, retries = 3, headers = None):\n",
        "        for i in range(retries):\n",
        "            try:\n",
        "                headers = {\n",
        "                    'User-Agent' : random.choice(self.user_agent)\n",
        "                }\n",
        "\n",
        "                response = self.session.post(url, data = data, headers = headers)\n",
        "                response.raise_for_status()\n",
        "                time.sleep(random.random())\n",
        "                return response\n",
        "\n",
        "            except requests.exceptions.HTTPError as e:\n",
        "                if e.response.status_code == 403:\n",
        "                    logger.warning(f'requests get error: {type(e).__name__}-{e}, skipping')\n",
        "                    return None\n",
        "                else:\n",
        "                    logger.warning(f'requests get error on attempt {i + 1}, {type(e).__name__}-{e}')\n",
        "                    time.sleep(3)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f'requests get error on attempt {i + 1}, {type(e).__name__}-{e}')\n",
        "                time.sleep(3)\n",
        "\n",
        "    def _get(self, url, retries = 3, headers = None):\n",
        "        for i in range(retries):\n",
        "            try:\n",
        "                headers = {\n",
        "                    'User-Agent' : random.choice(self.user_agent)\n",
        "                }\n",
        "\n",
        "                response = self.session.get(url, headers = headers)\n",
        "                response.raise_for_status()\n",
        "                time.sleep(random.random())\n",
        "                return response\n",
        "\n",
        "            except requests.exceptions.HTTPError as e:\n",
        "                if e.response.status_code == 403:\n",
        "                    logger.warning(f'requests get error: {type(e).__name__}-{e}, skipping')\n",
        "                    return None\n",
        "                else:\n",
        "                    logger.warning(f'requests get error on attempt {i + 1}, {type(e).__name__}-{e}')\n",
        "                    time.sleep(3)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f'requests get error on attempt {i + 1}, {type(e).__name__}-{e}')\n",
        "                time.sleep(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDLNFO-iy6sq"
      },
      "outputs": [],
      "source": [
        "api = Interface()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcfQftQFy_Xk"
      },
      "outputs": [],
      "source": [
        "class Scraper():\n",
        "    def __init__(self, api):\n",
        "        self.api = api\n",
        "        self.dataframe = pd.DataFrame(columns = ['index'])\n",
        "\n",
        "    def __get__animas(self, keyword = '动漫', max_num = 1000, start = 795):\n",
        "        try:\n",
        "            url = 'https://search.douban.com/movie/subject_search'\n",
        "            while len(self.dataframe) < max_num:\n",
        "                payload = {\n",
        "                    'search_text' : keyword,\n",
        "                    'start' : len(self.dataframe) + start,\n",
        "                }\n",
        "\n",
        "                response = self.api._post(url, payload)\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "                indexes = re.findall(r'\"id\":\\s*(\\d+)', soup.find('script', {'type' : 'text/javascript'}).text)\n",
        "                print(indexes)\n",
        "                self.dataframe = pd.concat([self.dataframe, pd.DataFrame(indexes, columns = ['index'])], ignore_index = True)\n",
        "\n",
        "                logger.info(f'Get {len(self.dataframe)} animas')\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f'Get animas error: {type(e).__name__}-{e}')\n",
        "\n",
        "    def __save__animas(self, path = 'data/animas.csv'):\n",
        "        self.dataframe.to_csv(path, index = False)\n",
        "\n",
        "    def run(self):\n",
        "        self.__get__animas()\n",
        "        self.__save__animas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekivkgto0pa-"
      },
      "outputs": [],
      "source": [
        "scraper = Scraper(api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cKjhfmV00wUv"
      },
      "outputs": [],
      "source": [
        "scraper.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbAL5f1b2AUlNJQDeZdjqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}